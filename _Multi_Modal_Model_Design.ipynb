{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOO+qCXdxKBYxfJDTNNpZFR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/OneFineStarstuff/blob/main/_Multi_Modal_Model_Design.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Example: A simple model definition\n",
        "class MultimodalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultimodalModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')  # BERT for text\n",
        "        self.fc_image = nn.Linear(256 * 256, 128)  # Example for image input (flattened 256x256 image)\n",
        "        self.fc_sensor = nn.Linear(10, 128)  # Example for sensor data (10 features)\n",
        "        self.fc_final = nn.Linear(128 + 128 + 768, 1)  # Final output layer for binary classification\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, image_data, sensor_data):\n",
        "        # Text data processing with BERT\n",
        "        text_outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        text_embedding = text_outputs.pooler_output  # Use the pooled output\n",
        "\n",
        "        # Image data processing\n",
        "        image_embedding = torch.flatten(image_data, 1)  # Flatten image data to a vector\n",
        "        image_embedding = self.fc_image(image_embedding)\n",
        "\n",
        "        # Sensor data processing\n",
        "        sensor_embedding = self.fc_sensor(sensor_data)\n",
        "\n",
        "        # Concatenate all embeddings and pass through the final layer\n",
        "        combined = torch.cat((text_embedding, image_embedding, sensor_embedding), dim=1)\n",
        "        output = self.fc_final(combined)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Prepare tokenizer (BERT)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Sample DataLoader setup (replace with actual data loading logic)\n",
        "class MultimodalDataset(Dataset):\n",
        "    def __init__(self, text_data, image_data, sensor_data, labels):\n",
        "        self.text_data = text_data\n",
        "        self.image_data = image_data\n",
        "        self.sensor_data = sensor_data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.text_data[idx]\n",
        "        image = self.image_data[idx]\n",
        "        sensor = self.sensor_data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize text\n",
        "        encoding = tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),  # Remove batch dimension\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),  # Remove batch dimension\n",
        "            'image': torch.tensor(image, dtype=torch.float32),\n",
        "            'sensor': torch.tensor(sensor, dtype=torch.float32),\n",
        "            'label': torch.tensor(label, dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "# Dummy data (replace with actual dataset)\n",
        "text_data = [\"This is a sample text.\", \"Another sample text.\"]\n",
        "image_data = [np.random.rand(256, 256), np.random.rand(256, 256)]  # Random image data\n",
        "sensor_data = [np.random.rand(10), np.random.rand(10)]  # Random sensor data (10 features)\n",
        "labels = [0, 1]  # Binary labels\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = MultimodalDataset(text_data, image_data, sensor_data, labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "\n",
        "# Initialize model, optimizer, and loss function\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MultimodalModel().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n",
        "\n",
        "# Early stopping parameters\n",
        "best_val_loss = float('inf')\n",
        "patience = 3\n",
        "epochs_since_improvement = 0\n",
        "best_model = None\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 20\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        image_data = batch['image'].to(device)\n",
        "        sensor_data = batch['sensor'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(input_ids, attention_mask, image_data, sensor_data)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(output.squeeze(1), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Compute accuracy (if binary classification)\n",
        "        predicted = torch.sigmoid(output).round()\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "        total_predictions += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    # Validation (can add a validation set here)\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            image_data = batch['image'].to(device)\n",
        "            sensor_data = batch['sensor'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            output = model(input_ids, attention_mask, image_data, sensor_data)\n",
        "            loss = criterion(output.squeeze(1), labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            predicted = torch.sigmoid(output).round()\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "\n",
        "    val_loss = val_loss / len(train_loader)\n",
        "    val_accuracy = correct_predictions / total_predictions\n",
        "\n",
        "    print(f\"Epoch {epoch}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Epoch {epoch}/{num_epochs}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = model.state_dict()  # Save the best model\n",
        "        epochs_since_improvement = 0\n",
        "    else:\n",
        "        epochs_since_improvement += 1\n",
        "\n",
        "    if epochs_since_improvement >= patience:\n",
        "        print(f\"Early stopping on epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "# Save the best model\n",
        "if best_model is not None:\n",
        "    torch.save(best_model, 'best_model.pth')\n",
        "    print(\"Best model saved as 'best_model.pth'\")\n",
        "\n",
        "# Inference Phase\n",
        "# Example inference with the best model\n",
        "test_data = [\"This is a test text.\"]\n",
        "image_test = [np.random.rand(256, 256)]  # Random test image\n",
        "sensor_test = [np.random.rand(10)]  # Random test sensor data\n",
        "\n",
        "# Tokenize the test data\n",
        "test_encoding = tokenizer(test_data, padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n",
        "text_input_ids = test_encoding['input_ids'].to(device)\n",
        "text_attention_mask = test_encoding['attention_mask'].to(device)\n",
        "\n",
        "# Prepare the input tensors for the image and sensor data\n",
        "image_tensor = torch.stack([torch.tensor(img, dtype=torch.float32) for img in image_test]).to(device)\n",
        "sensor_tensor = torch.tensor(sensor_test, dtype=torch.float32).to(device)\n",
        "\n",
        "# Load the best model for inference\n",
        "best_model = MultimodalModel().to(device)  # Reinitialize the model\n",
        "best_model.load_state_dict(torch.load('best_model.pth', weights_only=True))  # Load the saved model's state_dict\n",
        "best_model.eval()\n",
        "\n",
        "# Make prediction\n",
        "with torch.no_grad():\n",
        "    output = best_model(text_input_ids, text_attention_mask, image_tensor, sensor_tensor)\n",
        "    prediction = torch.sigmoid(output).cpu().numpy()\n",
        "    print(f\"Prediction: {prediction}\")"
      ],
      "metadata": {
        "id": "kpQqNWgFUM7U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}