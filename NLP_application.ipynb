{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPNwsfsNylv8uWVpb7tg01W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/OneFineStarstuff/blob/main/NLP_application.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "b4ASgso4FYOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flask pandas sklearn torch prometheus_client evidently lime shap redis kafka-python mlflow"
      ],
      "metadata": {
        "id": "yvs0gR4k__Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ajoqgdvs6lmr"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import pandas as pd\n",
        "from flask import Flask, request, jsonify\n",
        "import numpy as np\n",
        "import redis\n",
        "from prometheus_client import start_http_server, Counter\n",
        "import json\n",
        "from kafka import KafkaProducer\n",
        "import mlflow\n",
        "\n",
        "# Load and prepare dataset (example assumes a DataFrame with 'text' and 'label' columns)\n",
        "data = pd.read_csv(\"dataset.csv\")  # Replace with your file\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(data['text'], data['label'], test_size=0.2)\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)  # Adjust num_labels\n",
        "\n",
        "# Tokenize data\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)\n",
        "\n",
        "# Convert data to PyTorch format\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = Dataset(train_encodings, list(train_labels))\n",
        "val_dataset = Dataset(val_encodings, list(val_labels))\n",
        "\n",
        "# Define training arguments and trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
        "    precision = precision_score(labels, predictions, average=\"weighted\")\n",
        "    recall = recall_score(labels, predictions, average=\"weighted\")\n",
        "    return {\"accuracy\": accuracy, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "# Add compute_metrics to the Trainer\n",
        "trainer.compute_metrics = compute_metrics\n",
        "\n",
        "# Re-run evaluation\n",
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)\n",
        "\n",
        "# Save model and tokenizer for later use\n",
        "model.save_pretrained(\"./model\")\n",
        "tokenizer.save_pretrained(\"./model\")\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    data = request.json\n",
        "    text = data[\"text\"]\n",
        "\n",
        "    # Tokenize input text\n",
        "    encodings = tokenizer([text], truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "    # Make predictions\n",
        "    outputs = model(**encodings)\n",
        "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    # Log prediction and feedback if provided\n",
        "    feedback = data.get(\"feedback\")\n",
        "\n",
        "    if feedback:\n",
        "        with open(\"feedback_log.csv\", \"a\") as log_file:\n",
        "            log_file.write(f\"{text},{prediction},{feedback}\\n\")\n",
        "\n",
        "    return jsonify({\"prediction\": prediction})\n",
        "\n",
        "# Start Prometheus server for monitoring metrics\n",
        "start_http_server(8000)\n",
        "inference_requests = Counter(\"inference_requests_total\", \"Total inference requests\")\n",
        "\n",
        "@app.route(\"/predict_with_counter\", methods=[\"POST\"])\n",
        "def predict_with_counter():\n",
        "    inference_requests.inc()  # Increment counter for each request\n",
        "    return predict()\n",
        "\n",
        "# Kafka producer setup for feedback logging\n",
        "producer = KafkaProducer(\n",
        "    bootstrap_servers=['localhost:9092'],\n",
        "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
        ")\n",
        "\n",
        "@app.route(\"/feedback\", methods=[\"POST\"])\n",
        "def feedback():\n",
        "    data = request.json\n",
        "    text = data[\"text\"]\n",
        "\n",
        "    # Send feedback data to Kafka topic\n",
        "    producer.send(\"feedback_topic\", {\"text\": text})\n",
        "\n",
        "    return jsonify({\"status\": \"Feedback sent\"})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)\n",
        "\n",
        "# Redis cache setup for caching predictions\n",
        "cache = redis.Redis(host='localhost', port=6379)\n",
        "\n",
        "def get_prediction(input_data):\n",
        "    if cache.exists(input_data):\n",
        "        return cache.get(input_data)\n",
        "\n",
        "    encodings = tokenizer([input_data], truncation=True, padding=True, max_length=128)\n",
        "\n",
        "    outputs = model(**encodings)\n",
        "\n",
        "    prediction = torch.argmax(outputs.logits).item()\n",
        "\n",
        "    cache.set(input_data, prediction)\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# Example of using MLflow for tracking experiments and models\n",
        "mlflow.start_run()\n",
        "mlflow.log_param(\"model_version\", \"1.0\")\n",
        "mlflow.log_metric(\"accuracy\", eval_results['eval_accuracy'])\n",
        "mlflow.sklearn.log_model(model, \"model\")\n",
        "mlflow.end_run()"
      ]
    }
  ]
}