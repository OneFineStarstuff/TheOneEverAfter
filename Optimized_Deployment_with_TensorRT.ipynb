{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPf0VNX0t7AbZViosyqdH8n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/OneFineStarstuff/blob/main/Optimized_Deployment_with_TensorRT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorrt torch torch2trt"
      ],
      "metadata": {
        "id": "_qiJNMzioUQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the torch2trt repository\n",
        "!git clone https://github.com/NVIDIA-AI-IOT/torch2trt.git\n",
        "!cd torch2trt\n",
        "\n",
        "# Install torch2trt\n",
        "!sudo python3 setup.py install"
      ],
      "metadata": {
        "id": "kf8PZHNaqopY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA-AI-IOT/torch2trt.git"
      ],
      "metadata": {
        "id": "i_1rO6IBpyN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd torch2trt"
      ],
      "metadata": {
        "id": "4PrayN6Ap7U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo python3 setup.py install"
      ],
      "metadata": {
        "id": "uRfWvNz5p-9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y --no-install-recommends \\\n",
        "    libnvinfer8=8.x.x-1+cuda11.x \\\n",
        "    libnvinfer-plugin8=8.x.x-1+cuda11.x \\\n",
        "    libnvparsers8=8.x.x-1+cuda11.x \\\n",
        "    libnvonnxparsers8=8.x.x-1+cuda11.x \\\n",
        "    libnvinfer-bin=8.x.x-1+cuda11.x \\\n",
        "    libnvinfer-dev=8.x.x-1+cuda11.x \\\n",
        "    libnvinfer-plugin-dev=8.x.x-1+cuda11.x \\\n",
        "    libnvparsers-dev=8.x.x-1+cuda11.x \\\n",
        "    libnvonnxparsers-dev=8.x.x-1+cuda11.x \\\n",
        "    python3-libnvinfer=8.x.x-1+cuda11.x \\\n",
        "    python3-libnvinfer-dev=8.x.x-1+cuda11.x"
      ],
      "metadata": {
        "id": "GZE4nGU7qY_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorrt"
      ],
      "metadata": {
        "id": "yP7L6dSBqz2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you are in the correct directory\n",
        "cd /content/torch2trt/torch2trt\n",
        "\n",
        "# Check the directory for flattener module\n",
        "ls"
      ],
      "metadata": {
        "id": "AKSEYqY9xg5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!docker pull nvcr.io/nvidia/pytorch:xx.xx-py3  # Replace xx.xx with the desired version"
      ],
      "metadata": {
        "id": "DqJNdJA1rnOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!docker run --gpus all -it --rm nvcr.io/nvidia/pytorch:xx.xx-py3"
      ],
      "metadata": {
        "id": "sfUMGipZrrUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2ibuuROn3yY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch2trt import torch2trt, TRTModule\n",
        "\n",
        "# Load the PyTorch model\n",
        "model = torch.load(\"model.pth\").eval().cuda()\n",
        "\n",
        "# Create example input tensor\n",
        "example_input = torch.randn(1, 3, 224, 224).cuda()  # Adjust the shape based on your model's input\n",
        "\n",
        "# Convert the PyTorch model to TensorRT\n",
        "trt_model = torch2trt(model, [example_input])\n",
        "\n",
        "# Save the TensorRT model\n",
        "torch.save(trt_model.state_dict(), \"trt_model.pth\")\n",
        "\n",
        "# Load the TensorRT model\n",
        "trt_model = TRTModule()\n",
        "trt_model.load_state_dict(torch.load(\"trt_model.pth\"))\n",
        "\n",
        "# Perform inference\n",
        "input_data = torch.randn(1, 3, 224, 224).cuda()  # Adjust the shape based on your model's input\n",
        "inference_output = trt_model(input_data)\n",
        "\n",
        "print(inference_output)"
      ]
    }
  ]
}